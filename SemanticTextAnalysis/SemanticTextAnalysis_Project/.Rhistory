length(index_sorted)
# result: 1
length(indexList)
# result: 3
# SORTING THE LISTS ACCORDING TO THE FREQUENCY COUNT  ------------- end
# query optimization ----------
# TODO:
# we want to look for the words "of" AND "Friday"
# let's look throught the lists with fewer elements first
# query optimization (AND) ---------- end
indexList[[c(1,371)]]
test1 <- list( c(a='a',b='b',c='c'), c(a='d',b='e',c='f'))
as.data.frame(test1)
df =as.data.frame(test1)
df =as.data.frame(test1)
test1 <- list( c(a='a',b='b',c='c'), c(a='d',b='e',c='f'))
df =as.data.frame(test1)
test2 <- list( c('a','b','c'), c(a='d',b='e',c='f'))
as.data.frame(test2)
df2 = as.data.frame(test2)
test2
df <- data.frame(matrix(unlist(indexList), nrow=length(indexList), byrow=T))
df <- data.frame(matrix(unlist(indexList), nrow=length(indexList)))
df <- data.frame(matrix(unlist(indexList), nrow=length(indexList), byrow=T))
indexList[[c(1,position)]]
indexList[[c(2,371)]]
indexList[[c(2,1)]]
indexList
indexList[[c(1,1)]]
indexList[[c(1,2)]]
length(indexList[[1]])
length(indexList[[1]])
# remove all variables
rm(list=ls(all=TRUE))
# load in the files
news1 = scan("news1.txt", what="character")
news2 = scan("news2.txt", what="character")
news3 = scan("news3.txt", what="character")
news4 = scan("news4.txt", what="character")
news5 = scan("news5.txt", what="character")
# put all articles in a list
newsArticles = list(news1, news2, news3, news4, news5); # list of all articles
#list of all words
allWords = union(news1, news2);
allWords = union(allWords, news3);
allWords = union(allWords, news4);
allWords = union(allWords, news5);
# make index list with 727 entries and 1 column set to NULL
indexList = list(rep(list(c()), times=length(allWords)));
# make counter list where all data is set to default zero
countList =list(rep(list(c(0)), times=length(allWords)));
counter = 0;
# look through all words and set document ID
for (i in 1:length(allWords)) # loop through all words
{
for (j in 1:length(newsArticles)) # loop through all articles
{
if (is.element(allWords[[i]], newsArticles[[j]])) # check if word matches article
{
indexList[[1]][[i]] = union(indexList[[1]][[i]],j); # set document ID to list
counter = countList[[1]][[i]];
counter = counter + 1;
countList[[1]][[i]] = counter;
}
}
}
# set the second element to all the words
indexList[[2]] =  allWords;
indexList[[3]] = countList[[1]];
# NOTE: list is too long to be shown in Environment list
indexList[[1]] # see all document IDs
indexList[[2]] # see all words
# simple tests ----------------
# find the dictionary entry that contains word "of"
position = match("of", indexList[[2]]) # position of word in total words
# retrive the document IDs in that position: document 1+2+3+4+5
indexList[[c(1,position)]]
# searches for word number 371: "respectively
indexList[[c(2,371)]]
# how many times does the word "respectively" occur? 1 time
length(indexList[[1]])
# what document(s) includes the word "respectively"? document 2
indexList[[c(1,371)]]
# simple test ---------------- end
# SORTING THE LISTS ACCORDING TO THE FREQUENCY COUNT -------------
# rename the columns
names(indexList)[1] = "ID";
names(indexList)[2] = "Word";
names(indexList)[3] = "Freq";
# sort by freq, then id, then word
# inspired by: http://www.ats.ucla.edu/stat/r/faq/sort.htm
# this does not work?
index_sorted = indexList[order(indexList[3], indexList[1], indexList[2])]
length(index_sorted)
# result: 1
length(indexList)
# result: 3
# SORTING THE LISTS ACCORDING TO THE FREQUENCY COUNT  ------------- end
# query optimization ----------
# TODO:
# we want to look for the words "of" AND "Friday"
# let's look throught the lists with fewer elements first
# query optimization (AND) ---------- end
length(indexList[[1]])
indexList[[c(1,371)]]
length(indexList[[3]])
length(indexList[[c(3,371)]])
# remove all variables
rm(list=ls(all=TRUE))
# load in the files
news1 = scan("news1.txt", what="character")
news2 = scan("news2.txt", what="character")
news3 = scan("news3.txt", what="character")
news4 = scan("news4.txt", what="character")
news5 = scan("news5.txt", what="character")
# put all articles in a list
newsArticles = list(news1, news2, news3, news4, news5); # list of all articles
#list of all words
allWords = union(news1, news2);
allWords = union(allWords, news3);
allWords = union(allWords, news4);
allWords = union(allWords, news5);
# make index list with 727 entries and 1 column set to NULL
indexList = list(rep(list(c()), times=length(allWords)));
# make counter list where all data is set to default zero
countList =list(rep(list(c(0)), times=length(allWords)));
counter = 0;
# look through all words and set document ID
for (i in 1:length(allWords)) # loop through all words
{
for (j in 1:length(newsArticles)) # loop through all articles
{
if (is.element(allWords[[i]], newsArticles[[j]])) # check if word matches article
{
indexList[[1]][[i]] = union(indexList[[1]][[i]],j); # set document ID to list
counter = countList[[1]][[i]];
counter = counter + 1;
countList[[1]][[i]] = counter;
}
}
}
# set the second element to all the words
indexList[[2]] =  allWords;
indexList[[3]] = countList[[1]];
# NOTE: list is too long to be shown in Environment list
indexList[[1]] # see all document IDs
indexList[[2]] # see all words
# simple tests ----------------
# find the dictionary entry that contains word "of"
position = match("of", indexList[[2]]) # position of word in total words
# retrive the document IDs in that position: document 1+2+3+4+5
indexList[[c(1,position)]]
# searches for word number 371: "respectively
indexList[[c(2,371)]]
# how many times does the word "respectively" occur? 1 time
length(indexList[[c(3,371)]])
# what document(s) includes the word "respectively"? document 2
indexList[[c(1,371)]]
# simple test ---------------- end
# SORTING THE LISTS ACCORDING TO THE FREQUENCY COUNT -------------
# rename the columns
names(indexList)[1] = "ID";
names(indexList)[2] = "Word";
names(indexList)[3] = "Freq";
# sort by freq, then id, then word
# inspired by: http://www.ats.ucla.edu/stat/r/faq/sort.htm
# this does not work?
index_sorted = indexList[order(indexList[3], indexList[1], indexList[2])]
length(index_sorted)
# result: 1
length(indexList)
# result: 3
# SORTING THE LISTS ACCORDING TO THE FREQUENCY COUNT  ------------- end
# query optimization ----------
# TODO:
# we want to look for the words "of" AND "Friday"
# let's look throught the lists with fewer elements first
# query optimization (AND) ---------- end
index_sorted = indexList[order(indexList[3], indexList[1], indexList[2])]
index_sorted
length(index_sorted)
length(indexList)
# remove all variables
rm(list=ls(all=TRUE))
# load in the files
news1 = scan("news1.txt", what="character")
news2 = scan("news2.txt", what="character")
news3 = scan("news3.txt", what="character")
news4 = scan("news4.txt", what="character")
news5 = scan("news5.txt", what="character")
# put all articles in a list
newsArticles = list(news1, news2, news3, news4, news5); # list of all articles
#list of all words
allWords = union(news1, news2);
allWords = union(allWords, news3);
allWords = union(allWords, news4);
allWords = union(allWords, news5);
# make index list with 727 entries and 1 column set to NULL
indexList = list(rep(list(c()), times=length(allWords)));
# make counter list where all data is set to default zero
countList =list(rep(list(c(0)), times=length(allWords)));
counter = 0;
# look through all words and set document ID
for (i in 1:length(allWords)) # loop through all words
{
for (j in 1:length(newsArticles)) # loop through all articles
{
if (is.element(allWords[[i]], newsArticles[[j]])) # check if word matches article
{
indexList[[1]][[i]] = union(indexList[[1]][[i]],j); # set document ID to list
counter = countList[[1]][[i]];
counter = counter + 1;
countList[[1]][[i]] = counter;
}
}
}
# set the second element to all the words
indexList[[2]] =  allWords;
indexList[[3]] = countList[[1]];
# NOTE: list is too long to be shown in Environment list
indexList[[1]] # see all document IDs
indexList[[2]] # see all words
# simple tests ----------------
# find the dictionary entry that contains word "of"
position = match("of", indexList[[2]]) # position of word in total words
# retrive the document IDs in that position: document 1+2+3+4+5
indexList[[c(1,position)]]
# searches for word number 371: "respectively
indexList[[c(2,371)]]
# how many times does the word "respectively" occur? 1 time
length(indexList[[c(3,371)]])
# what document(s) includes the word "respectively"? document 2
indexList[[c(1,371)]]
# simple test ---------------- end
# SORTING THE LISTS ACCORDING TO THE FREQUENCY COUNT -------------
# rename the columns
names(indexList)[1] = "ID";
names(indexList)[2] = "Word";
names(indexList)[3] = "Freq";
# sort by freq, then id, then word
# inspired by: http://www.ats.ucla.edu/stat/r/faq/sort.htm
# this does not work?
index_sorted = indexList[order(indexList[3], indexList[1], indexList[2])]
length(index_sorted)
# result: 1
length(indexList)
# result: 3
# SORTING THE LISTS ACCORDING TO THE FREQUENCY COUNT  ------------- end
# query optimization ----------
# TODO:
# we want to look for the words "of" AND "Friday"
# let's look throught the lists with fewer elements first
# query optimization (AND) ---------- end
indexList[[c(1,371)]]
length(indexList[[c(3,position)]])
df = do.call(rbind.data.frame, indexList)
library(rlist)
library(pipeR)
people <- list.load("http://renkun.me/rlist-tutorial/data/sample.json")
myList <- list(
A = 1:3,
B = 1:5)
myList
indexList
myList
data.frame(
lNames = rep(names(myList), lapply(myList, length)),
lVal = unlist(myList))
myList
df = data.frame(
lNames = rep(names(myList), lapply(myList, length)),
lVal = unlist(myList))
index_sorted = df[order(df[1], df[2])]
df.sort = df[order(df[1],df[2])];
df.sort = df[order(df[1], df[2])]
df2 = df[order(df[1], df[2])]
df2 = df[order(df[1], df[2])]
df = data.frame(
lNames = rep(names(myList), lapply(myList, length)),
lVal = unlist(myList))
df2 = df[order(df[1], df[2])]
df = data.frame(
lNames = rep(names(myList), lapply(myList, length)),
lVal = unlist(myList))
df
attach(mtcars)
mtcars
mtCars = attach(mtcars)
?attach
mtCars = attach(mtcars)
attach(mtcars)
# remove all variables
rm(list=ls(all=TRUE))
# load in the files
news1 = scan("news1.txt", what="character")
news2 = scan("news2.txt", what="character")
news3 = scan("news3.txt", what="character")
news4 = scan("news4.txt", what="character")
news5 = scan("news5.txt", what="character")
# put all articles in a list
newsArticles = list(news1, news2, news3, news4, news5); # list of all articles
#list of all words
allWords = union(news1, news2);
allWords = union(allWords, news3);
allWords = union(allWords, news4);
allWords = union(allWords, news5);
# make index list with 727 entries and 1 column set to NULL
indexList = list(rep(list(c()), times=length(allWords)));
# make counter list where all data is set to default zero
countList =list(rep(list(c(0)), times=length(allWords)));
counter = 0;
# look through all words and set document ID
for (i in 1:length(allWords)) # loop through all words
{
for (j in 1:length(newsArticles)) # loop through all articles
{
if (is.element(allWords[[i]], newsArticles[[j]])) # check if word matches article
{
indexList[[1]][[i]] = union(indexList[[1]][[i]],j); # set document ID to list
counter = countList[[1]][[i]];
counter = counter + 1;
countList[[1]][[i]] = counter;
}
}
}
# set the second element to all the words
indexList[[2]] =  allWords;
indexList[[3]] = countList[[1]];
# NOTE: list is too long to be shown in Environment list
indexList[[1]] # see all document IDs
indexList[[2]] # see all words
# simple tests ----------------
# find the dictionary entry that contains word "of"
position = match("of", indexList[[2]]) # position of word in total words
# retrive the document IDs in that position: document 1+2+3+4+5
indexList[[c(1,position)]]
# searches for word number 371: "respectively
indexList[[c(2,371)]]
# how many times does the word "respectively" occur? 1 time
length(indexList[[c(3,position)]])
# what document(s) includes the word "respectively"? document 2
indexList[[c(1,371)]]
# simple test ---------------- end
# SORTING THE LISTS ACCORDING TO THE FREQUENCY COUNT -------------
# rename the columns
names(indexList)[1] = "ID";
names(indexList)[2] = "Word";
names(indexList)[3] = "Freq";
# sort by freq, then id, then word
# inspired by: http://www.ats.ucla.edu/stat/r/faq/sort.htm
# this does not work?
index_sorted = indexList[order(indexList[3], indexList[1], indexList[2])]
length(index_sorted)
# result: 1
length(indexList)
# result: 3
# SORTING THE LISTS ACCORDING TO THE FREQUENCY COUNT  ------------- end
# query optimization ----------
# TODO:
# we want to look for the words "of" AND "Friday"
# let's look throught the lists with fewer elements first
# query optimization (AND) ---------- end
# make list into dataframe
attach(mtCars)
attach(mtcars)
mtcars
m = mtcars
newdata <- mtcars[order(mpg),]
newdata
myList
myList <- list(
A = 1:3,
B = 1:5)
myList
nList = list(
Words = indexList[[2]],
IDs = indexList[[1]],
Frequency = indexList[[3]]
)
nList$Frequency
nList$Words
nList$IDs
df = data.frame(
lNames = rep(names(nList), lapply(nList, length)),
lVal = unlist(nList))
?data.frame
df = as.data.frame(nList)
indexList
indexList[[2]]
indexList[[1]]
test3 <- list(Row1 = c(a = "a", b = "b", c = "c"), Row2 = c(var1 = "d", var2 = "e",
var3 = "f"))
test3
nList
# remove all variables
rm(list=ls(all=TRUE))
# load in the files
news1 = scan("news1.txt", what="character")
news2 = scan("news2.txt", what="character")
news3 = scan("news3.txt", what="character")
news4 = scan("news4.txt", what="character")
news5 = scan("news5.txt", what="character")
# put all articles in a list
newsArticles = list(news1, news2, news3, news4, news5); # list of all articles
#list of all words
allWords = union(news1, news2);
allWords = union(allWords, news3);
allWords = union(allWords, news4);
allWords = union(allWords, news5);
# make index list with 727 entries and 1 column set to NULL
indexList = list(rep(list(c()), times=length(allWords)));
# make counter list where all data is set to default zero
countList =list(rep(list(c(0)), times=length(allWords)));
counter = 0;
# look through all words and set document ID
for (i in 1:length(allWords)) # loop through all words
{
for (j in 1:length(newsArticles)) # loop through all articles
{
if (is.element(allWords[[i]], newsArticles[[j]])) # check if word matches article
{
indexList[[1]][[i]] = union(indexList[[1]][[i]],j); # set document ID to list
counter = countList[[1]][[i]];
counter = counter + 1;
countList[[1]][[i]] = counter;
}
}
}
# set the second element to all the words
indexList[[2]] =  allWords;
indexList[[3]] = countList[[1]];
# NOTE: list is too long to be shown in Environment list
indexList[[1]] # see all document IDs
indexList[[2]] # see all words
# create a new list with proper column names ----
nList = list(
Words = indexList[[2]],
IDs = indexList[[1]],
Frequency = indexList[[3]]
)
# create a new list with proper column names ---- end
# simple tests ----------------
# find the dictionary entry that contains word "of"
position = match("of", indexList[[2]]) # position of word in total words
# retrive the document IDs in that position: document 1+2+3+4+5
indexList[[c(1,position)]]
# searches for word number 371: "respectively
indexList[[c(2,371)]]
# how many times does the word "respectively" occur? 1 time
length(indexList[[c(3,position)]])
# what document(s) includes the word "respectively"? document 2
indexList[[c(1,371)]]
# simple test ---------------- end
# SORTING THE LISTS ACCORDING TO THE FREQUENCY COUNT -------------
# rename the columns
names(indexList)[1] = "ID";
names(indexList)[2] = "Word";
names(indexList)[3] = "Freq";
# sort by freq, then id, then word
# inspired by: http://www.ats.ucla.edu/stat/r/faq/sort.htm
# this does not work?
index_sorted = indexList[order(indexList[3], indexList[1], indexList[2])]
length(index_sorted)
# result: 1
length(indexList)
# result: 3
# SORTING THE LISTS ACCORDING TO THE FREQUENCY COUNT  ------------- end
# query optimization ----------
# TODO:
# we want to look for the words "of" AND "Friday"
# let's look throught the lists with fewer elements first
# query optimization (AND) ---------- end
# make list into dataframe
nList
nList$Words
nList$Freq
nList$Frequency
as.data.frame(nList)
as.data.frame(test3)
test3 <- list(Row1 = c(a = "a", b = "b", c = "c"), Row2 = c(var1 = "d", var2 = "e",
var3 = "f"))
as.data.frame(test3)
test3
test3 <- list(Row1 = c(a = "a", b = "b", c = "c", d = "d1"), Row2 = c(var1 = "d", var2 = "e",
var3 = "f"))
test3
as.data.frame(test3)
test3 <- list(Row1 = c(a = "a", b = "b", c = "c"), Row2 = c(var1 = "d", var2 = "e",
var3 = "f"))
test3
as.data.frame(test3)
test3 <- list(Row1 = c(a = "a", b = "b", c = "c", d = "d1"), Row2 = c(var1 = "d", var2 = "e",
var3 = "f"))
test3
as.data.frame(test3)
sorted = nList[order(nList$Frequency, ])]
index_sorted = indexList[order(indexList[3], indexList[1], indexList[2])]
indexList[3]
index_sorted[[3]]
index_sorted[3]
length(indexList[[position]])
length(indexList[c(2,position]])
length(indexList[c(2,position])
indexList[[c(3,371)]]
2
indexList[[c(2,371)]]
indexList[[c(3,371)]]
indexList[[c(2,position)]]
indexList[[c(3,position)]]
position = match("of", indexList[[2]]) # position of word in total words
position
indexList[[c(1,position)]]
