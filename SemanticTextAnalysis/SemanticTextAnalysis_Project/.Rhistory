for (j in 1:length(newsArticles)) # loop through all articles
{
if (is.element(allWords[[i]], newsArticles[[j]])) # check if word matches article
{
tempPosition <- c();
for (k in 1:length(newsArticles[[j]]))
{
if (is.element(allWords[[i]], newsArticles[[j]][[k]]))
{
tempPosition = c(tempPosition, k);
}
}
# Store document ID j in extra column
positionList[[1]][[i]] = c(positionList[[1]][[i]],j,list(tempPosition));
}
}
}
position = match("Taliban", indexList[[2]]) # position of word in total words
indexList[[c(2,position)]]
ultimateList[[c(4,position)]] # word "following" is found in article 1 (position 2)
ultimateList = union(indexList,positionList );
#positionList[[1]][[1]]
#newsArticles[[1]][[1]][[4]]
position = match("world", indexList[[2]]) # position of word in total words
indexList[[c(1,position)]]
position = match("of", indexList[[2]]) # position of word in total words
indexList[[c(1,position)]]
position = match("Taliban", indexList[[2]]) # position of word in total words
indexList[[c(1,position)]]
position = match("maybe", indexList[[2]]) # position of word in total words
indexList[[c(1,position)]]
position = match("might", indexList[[2]]) # position of word in total words
indexList[[c(1,position)]]
position = match("can", indexList[[2]]) # position of word in total words
indexList[[c(1,position)]]
position = match("you", indexList[[2]]) # position of word in total words
indexList[[c(1,position)]]
position = match("news", indexList[[2]]) # position of word in total words
indexList[[c(1,position)]]
indexList[[c(2,position)]]
indexList[[c(3,position)]]
indexList[[c(3,position)]]
indexList[[c(1,position)]]
indexList[[c(1,position)]]
position = match("Taliban", indexList[[2]]) # position of word in total words
ultimateList[[c(4,position)]] # word "following" is found in article 1 (position 2)
ultimateList = union(indexList,positionList);
ultimateList[[c(4,position)]] # word "following" is found in article 1 (position 2)
# remove all variables
rm(list=ls(all=TRUE))
# load in the files
news1 = scan("news1.txt", what="character")
news2 = scan("news2.txt", what="character")
news3 = scan("news3.txt", what="character")
news4 = scan("news4.txt", what="character")
news5 = scan("news5.txt", what="character")
# put all articles in a list
newsArticles = list(news1, news2, news3, news4, news5); # list of all articles
#list of all unique
allWords = union(news1, news2);
allWords = union(allWords, news3);
allWords = union(allWords, news4);
allWords = union(allWords, news5);
# make index list with 727 entries and 1 column set to NULL
indexList = list(rep(list(c()), times=length(allWords)));
# make counter list where all data is set to default zero
countList =list(rep(list(c(0)), times=length(allWords)));
# look through all words and set document ID
for (i in 1:length(allWords)) # loop through all words
{
for (j in 1:length(newsArticles)) # loop through all articles
{
if (is.element(allWords[[i]], newsArticles[[j]])) # check if word matches article
{
indexList[[1]][[i]] = union(indexList[[1]][[i]],j); # set document ID to list
countList[[1]][[i]] =  countList[[1]][[i]] + 1; # increase frequency for this word by 1
}
}
}
indexList[[2]] =  allWords; # set the second element to all the words
indexList[[3]] = countList[[1]]; # set the third element to the frequency of the words
# rename the columns
names(indexList)[1] = "ID";
names(indexList)[2] = "Word";
names(indexList)[3] = "Freq";
# NOTE: list is too long to be shown in Environment list
indexList[[1]] # see all document IDs
indexList[[2]] # see all words
# find the dictionary entry that contains word "news"
position = match("news", indexList[[2]]) # position of word in total words
# TASK 1) Write a query for your index that returns all documents comntaining the search term
indexList[[c(1,position)]] # what document(s) includes the word "news"? Document 1 + 3 + 5
# searches for word "news"
indexList[[c(2,position)]]
# how many times does the word "news" occur? 3 times
indexList[[c(3,position)]]
# TASK 2) extend your query for AND a OR -----------
positionA = match("million", indexList[[2]]) # position of word in total words
positionB = match("Reuters", indexList[[2]]) # position of word in total words
A = indexList[[c(1,positionA)]] # document IDs with word "million"
B = indexList[[c(1,positionB)]] # document IDs with word "Reuters"
# OR comparsion
AB_OR = union(A,B);  # words "million" OR "Reuters" are found in article 1 + 3 + 5
# AND comparison
AB_AND = intersect(A,B); # words "million" AND "Reuters" are found in article 5
# TASK 3) extending index to "positindonal" Index -----
positionList = list(rep(list(c()), times=length(allWords)));
# look through all words and set document ID
for (i in 1:length(allWords)) # loop through all words
{
for (j in 1:length(newsArticles)) # loop through all articles
{
if (is.element(allWords[[i]], newsArticles[[j]])) # check if word matches article
{
tempPosition <- c();
for (k in 1:length(newsArticles[[j]]))
{
if (is.element(allWords[[i]], newsArticles[[j]][[k]]))
{
tempPosition = c(tempPosition, k);
}
}
# Store document ID j in extra column
positionList[[1]][[i]] = c(positionList[[1]][[i]],j,list(tempPosition));
}
}
}
totalList = union(indexList,positionList); # make total list with the new positional index
position = match("Taliban", indexList[[2]]) # look for word "Taliban"
# at what positions are the word "Taliban" stored? Document ID 1 at position 3 + 52 + 107 + 124
totalList[[c(4,position)]]
install.packages('tm');
library(tm);
news1 = scan("news1.txt", what="character")
rm(list=ls(all=TRUE))
reviews = read.csv("reviews.csv", stringsAsFactors = FALSE);
view(reviws)
View(reviws)
View(reviews)
View(news5)
news5 = scan("news5.txt", what="character")
View(news5)
## --- Created by Gustav Dahl, IM 2015 (October) --- ###
# remove all variables
rm(list=ls(all=TRUE))
# load in the files
news1 = scan("news1.txt", what="character")
news2 = scan("news2.txt", what="character")
news3 = scan("news3.txt", what="character")
news4 = scan("news4.txt", what="character")
news5 = scan("news5.txt", what="character")
View(news5)
# put all articles in a list
newsArticles = list(news1, news2, news3, news4, news5); # list of all articles
#list of all unique
allWords = union(news1, news2);
allWords = union(allWords, news3);
allWords = union(allWords, news4);
allWords = union(allWords, news5);
# make index list with 727 entries and 1 column set to NULL
indexList = list(rep(list(c()), times=length(allWords)));
# make counter list where all data is set to default zero
countList =list(rep(list(c(0)), times=length(allWords)));
# look through all words and set document ID
for (i in 1:length(allWords)) # loop through all words
{
for (j in 1:length(newsArticles)) # loop through all articles
{
if (is.element(allWords[[i]], newsArticles[[j]])) # check if word matches article
{
indexList[[1]][[i]] = union(indexList[[1]][[i]],j); # set document ID to list
countList[[1]][[i]] =  countList[[1]][[i]] + 1; # increase frequency for this word by 1
}
}
}
indexList[[2]] =  allWords; # set the second element to all the words
indexList[[3]] = countList[[1]]; # set the third element to the frequency of the words
# rename the columns
names(indexList)[1] = "ID";
names(indexList)[2] = "Word";
names(indexList)[3] = "Freq";
# NOTE: list is too long to be shown in Environment list
indexList[[1]] # see all document IDs
indexList[[2]] # see all words
# find the dictionary entry that contains word "news"
position = match("news", indexList[[2]]) # position of word in total words
# TASK 1) Write a query for your index that returns all documents comntaining the search term
indexList[[c(1,position)]] # what document(s) includes the word "news"? Document 1 + 3 + 5
# searches for word "news"
indexList[[c(2,position)]]
# how many times does the word "news" occur? 3 times
indexList[[c(3,position)]]
# TASK 2) extend your query for AND a OR -----------
positionA = match("million", indexList[[2]]) # position of word in total words
positionB = match("Reuters", indexList[[2]]) # position of word in total words
A = indexList[[c(1,positionA)]] # document IDs with word "million"
B = indexList[[c(1,positionB)]] # document IDs with word "Reuters"
# OR comparsion
AB_OR = union(A,B);  # words "million" OR "Reuters" are found in article 1 + 3 + 5
# AND comparison
AB_AND = intersect(A,B); # words "million" AND "Reuters" are found in article 5
# TASK 3) extending index to "positindonal" Index -----
positionList = list(rep(list(c()), times=length(allWords)));
# look through all words and set document ID
for (i in 1:length(allWords)) # loop through all words
{
for (j in 1:length(newsArticles)) # loop through all articles
{
if (is.element(allWords[[i]], newsArticles[[j]])) # check if word matches article
{
tempPosition <- c();
for (k in 1:length(newsArticles[[j]]))
{
if (is.element(allWords[[i]], newsArticles[[j]][[k]]))
{
tempPosition = c(tempPosition, k);
}
}
# Store document ID j in extra column
positionList[[1]][[i]] = c(positionList[[1]][[i]],j,list(tempPosition));
}
}
}
totalList = union(indexList,positionList); # make total list with the new positional index
position = match("Taliban", indexList[[2]]) # look for word "Taliban"
# at what positions are the word "Taliban" stored? Document ID 1 at position 3 + 52 + 107 + 124
totalList[[c(4,position)]]
View(totalList)
install.packages('tm');
library(tm);
#loading the data
reviews = read.csv("reviews.csv", stringsAsFactors = FALSE);
View(reviews)
install.packages("tm")
rm(list=ls(all=TRUE))
reviews = read.csv("reviews.csv", stringsAsFactors = FALSE);
View(reviews)
review_text = paste(reviews$text, collapse="");
review_source = VectorSource(review_text);
View(review_source)
corpus = Corpus(review_source);
corpus
?tm_map
?tm_map
?tm_map
corpus = tm_map(corpus, content_transformer(toLower));
corpus = tm_map(corpus, content_transformer(tolower));
corpus
corpus = tm_map(corpus, removePunctuation);
corpus = tm_map(corpus, stripWhitespace);
corpus = tm_map(corpus, removeWords, stopwords("english");
corpus = tm_map(corpus, removeWords, stopwords("english"));
stopwords
stopwords("en")
stopwords("dk")
stopwords("da")
stopwords("de")
#loading the data
reviews = read.csv("reviews.csv", stringsAsFactors = FALSE);
View(reviews)
# combine all review text together
review_text = paste(reviews$text, collapse="");
# setting up source and corpus
review_source = VectorSource(review_text);
corpus = Corpus(review_source);
# cleaning
corpus = tm_map(corpus, content_transformer(tolower));
corpus = tm_map(corpus, removePunctuation);
corpus = tm_map(corpus, stripWhitespace);
corpus = tm_map(corpus, removeWords, stopwords("english"));
corpus = tm_map(corpus, stripWhitespace);
corpus = tm_map(corpus, removeWords, stopwords("english"));
#loading the data
reviews = read.csv("reviews.csv", stringsAsFactors = FALSE);
View(reviews)
# combine all review text together
review_text = paste(reviews$text, collapse="");
# setting up source and corpus
review_source = VectorSource(review_text);
corpus = Corpus(review_source);
# cleaning
corpus = tm_map(corpus, content_transformer(tolower));
corpus = tm_map(corpus, removePunctuation);
corpus = tm_map(corpus, stripWhitespace);
corpus = tm_map(corpus, removeWords, stopwords("english"));
dtm
dtm = DocumentTermMatrix(corpus);
dtm2 = as.matrix(dtm);
dtm
dtm2
frequency = colSums(dtm2)
frequency
View(frequency)
frequency = sort(frequency, decreasing=TRUE);
frequency
str(frequency)
frequency = colSums(dtm2)
frequency
frequency = sort(frequency, decreasing=FALSE);
head(frequency)
frequency = colSums(dtm2)
frequency = sort(frequency, decreasing=FALSE);
# str(frequency)
head(frequency)
frequency = colSums(dtm2)
frequency = sort(frequency, decreasing=TRUE);
head(frequency)
install.packages('wordcloud');
?head
?names
head(words)
words = names(frequency);
head(words)
wordcloud(words[1:100], frequency[1:100]);
library(wordcloud);
wordcloud(words[1:100], frequency[1:100]);
?paste
review_text = paste(news1, news2, news3, news4, news5, collapse="");
# news articles loading
news1 = scan("news1.txt", what="character")
news2 = scan("news2.txt", what="character")
news3 = scan("news3.txt", what="character")
news4 = scan("news4.txt", what="character")
news5 = scan("news5.txt", what="character")
review_text = paste(news1, news2, news3, news4, news5, collapse="");
# setting up source and corpus
review_source = VectorSource(news_text);
corpus = Corpus(review_source);
# cleaning
corpus = tm_map(corpus, content_transformer(tolower));
corpus = tm_map(corpus, removePunctuation);
corpus = tm_map(corpus, stripWhitespace);
corpus = tm_map(corpus, removeWords, stopwords("english"));
# making document-term matrix
dtm = DocumentTermMatrix(corpus);
dtm2 = as.matrix(dtm);
# finding the most frequent terms
frequency = colSums(dtm2)
frequency = sort(frequency, decreasing=TRUE);
# str(frequency)
head(frequency) # 6 most common words
install.packages('wordcloud');
library(wordcloud);
words = names(frequency);
wordcloud(words[1:100], frequency[1:100]);
install.packages("wordcloud")
wordcloud(words[1:100], frequency[1:100]);
news_text = paste(news1, news2, news3, news4, news5, collapse="");
review_source = VectorSource(news_text);
corpus = Corpus(review_source);
corpus = tm_map(corpus, content_transformer(tolower));
corpus = tm_map(corpus, removePunctuation);
corpus = tm_map(corpus, stripWhitespace);
corpus = tm_map(corpus, removeWords, stopwords("english"));
dtm = DocumentTermMatrix(corpus);
dtm2 = as.matrix(dtm);
frequency = colSums(dtm2)
frequency = sort(frequency, decreasing=TRUE);
head(frequency) # 6 most common words
words = names(frequency);
wordcloud(words[1:100], frequency[1:100]);
review_source = VectorSource(review_text);
corpus = Corpus(review_source);
# cleaning
corpus = tm_map(corpus, removePunctuation);
corpus = tm_map(corpus, content_transformer(tolower));
corpus = tm_map(corpus, stripWhitespace);
# making document-term matrix
dtm = DocumentTermMatrix(corpus);
corpus = tm_map(corpus, removeWords, stopwords("english"));
dtm2 = as.matrix(dtm);
# finding the most frequent terms
frequency = colSums(dtm2)
frequency = sort(frequency, decreasing=TRUE);
# str(frequency)
head(frequency) # 6 most common words
words = names(frequency);
wordcloud(words[1:100], frequency[1:100]);
# from: https://deltadna.com/blog/text-mining-in-r-for-term-frequency/
#install.packages('tm');
#library(tm);
#loading the data
reviews = read.csv("reviews.csv", stringsAsFactors = FALSE);
#View(reviews) #view the data in a table
# combine all review text together
review_text = paste(reviews$text, collapse="");
# mine --------------
# news articles loading
#news1 = scan("news1.txt", what="character")
#news2 = scan("news2.txt", what="character")
#news3 = scan("news3.txt", what="character")
#news4 = scan("news4.txt", what="character")
#news5 = scan("news5.txt", what="character")
#news_text = paste(news1, news2, news3, news4, news5, collapse="");
## -----------
# setting up source and corpus
review_source = VectorSource(review_text);
corpus = Corpus(review_source);
# cleaning
corpus = tm_map(corpus, content_transformer(tolower));
corpus = tm_map(corpus, removePunctuation);
corpus = tm_map(corpus, stripWhitespace);
corpus = tm_map(corpus, removeWords, stopwords("english"));
# making document-term matrix
dtm = DocumentTermMatrix(corpus);
dtm2 = as.matrix(dtm);
# finding the most frequent terms
frequency = colSums(dtm2)
frequency = sort(frequency, decreasing=TRUE);
# str(frequency)
head(frequency) # 6 most common words
#install.packages('wordcloud');
#library(wordcloud);
words = names(frequency);
wordcloud(words[1:100], frequency[1:100]);
(int a = 2)
(a = 2)
txt <- system.file("texts", "txt", package = "tm")
(ovid <- VCorpus(DirSource(txt, encoding = "UTF-8"), readerControl = list(language = "lat")))
docs = c("This is tweet A", "This is tweet B");
VCorpus(VectorSource(docs));
reut21578 <- system.file("texts", "crude", package = "tm")
reuters <- VCorpus(DirSource(reut21578), readerControl = list(reader = readReut21578XMLasPlain))
install.packages("XML")
reut21578 <- system.file("texts", "crude", package = "tm")
reuters <- VCorpus(DirSource(reut21578), readerControl = list(reader = readReut21578XMLasPlain))
writeCorpus(ovid)
ovid
inspect(ovid[1:2])
print(ovid)
inspect(ovid)
rm(list=ls(all=TRUE))
# trying out tm main tutorial
# get files in texts directory
txt <- system.file("texts", "txt", package = "tm")
(ovid <- VCorpus(DirSource(txt, encoding = "UTF-8"), readerControl = list(language = "lat")))
#(variable) is the same as print(variable)
# read directly from vector sources
docs = c("This is tweet A", "This is tweet B");
VCorpus(VectorSource(docs));
# reuters XML file
#install.packages("XML")
reut21578 <- system.file("texts", "crude", package = "tm")
reuters <- VCorpus(DirSource(reut21578), readerControl = list(reader = readReut21578XMLasPlain))
# export
writeCorpus(ovid)
# little details
print(ovid)
# more details
inspect(ovid[1:2])
# more details
meta(ovid)
meta(ovid[1:2])
meta(ovid[[2])
meta(ovid[[2]])
meta(ovid[[2]], "id");
identical(ovid[[2]], ovid[["ovid_2.txt"]])
identical(ovid[[2]], ovid[["ovidasd_2.txt"]])
writeLines("hejsa")
writeLines(as.character(ovid))
writeLines(as.character(ovid[[2]]))
writeLines(as.character(ovid[2]))
as.character(ovid[[2]])
?lapply
lapply(ovid[1:2], as.character)
writeLines(lapply(ovid[1:2], as.character))
lapply(ovid[1:2], as.character)
reuters <- tm_map(reuters, stripWhitespace)
reuters <- tm_map(reuters, content_transformer(tolower))
?gsub
reuters <- tm_map(reuters, removeWords, stopwords("english"))
tm_map(reuters, stemDocument)
install.packages("SnowballC")
tm_map(reuters, stemDocument)
install.packages('SnowballC');
tm_map(reuters, stemDocument)
reuters_stemmed = tm_map(reuters, stemDocument)
writeLines(as.character(ovid[[2]]))
writeLines(as.character(reuters))
writeLines(as.character(reuters[[2]]))
writeLines(as.character(reuters_stemmed[[2]]))
idx <- meta(reuters, "id") == '237' & meta(reuters, "heading") == 'INDONESIA SEEN AT CROSSROADS OVER ECONOMIC CHANGE'
reuters[idx]
idx <- meta(reuters, "id") == '237' | meta(reuters, "id") == '238'
reuters[idx]
idx <- meta(reuters, "id") == '237' | meta(reuters, "id") == '238'
reuters[idx]
idx <- meta(reuters, "id") == '1237' | meta(reuters, "id") == '238'
reuters[idx]
idx <- meta(reuters, "id") == '237' | meta(reuters, "id") == '230'
reuters[idx]
meta(ovid[[2]]);
meta(reuters, "id")
idx <- meta(reuters, "id") == '237' | meta(reuters, "id") == '704'
reuters[idx]
meta(reuters)
meta(reuters[[2]])
?DublinCore
DublinCore(crude[[1]], "Creator") <- "Ano Nymous"
DublinCore(ovid[[1]], "Creator") = "Ano Nymous"
DublinCore(ovid[[1]], "Creator")
meta(ovid[[1]])
meta(ovid[[1]], tag = "test", type = "corpus") <- "test meta"
meta(ovid[[1]])
meta(ovid[[1]], type = "corpus")
meta(ovid[[1]])
$test
meta(crude, type = "corpus")
$test
attr(,"class")
meta(ovid[[1]], "foo") <- letters[1:20]
meta(ovid[[1]])
